{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducing Knowledge Graphs\n",
    "In complex fields, such as science and medicine, the sheer amount of data and literature available on specific topics is hard to overstate. The same goes for knowledge management in established companies and industries where, over time, institutional knowledge in the form of textual information builds up, becoming too large to sensibly disseminate. In both of these case, a knowledge graph may help to alleviate issues associated with too much disparate information.\n",
    "\n",
    "The quality of text data has a large impact on the preparation of data for knowledge graph ingestion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the data for our knowledge graph\n",
    "\n",
    "Knowledge graphs typically contain relationships that represent commonalities between related documents and are built up using the content within those documents text. For this reason, a large part of knowledge graph construction is cleaning and preparing that text for later graph creation.\n",
    "\n",
    "Let’s begin by taking a look at the raw abstract data in 20k_abstracts.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the raw abstract data\n",
    "import csv\n",
    "with open('./data/20k_abstracts.txt') as c:\n",
    "    reader = csv.reader(c, delimiter='\\t')\n",
    "    data = [line for line in reader if line != []]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our data loaded, we can now convert it into a different format. We want to concatenate\n",
    "each of the sentences in an abstract into one whole abstract – at present the sentences are on\n",
    "different lines – as well as removing unnecessary data.\n",
    "\n",
    "Now, we can open our for loop and add some logic. We know the sentences begin from the\n",
    "second line, so we can slice our list of lists to process and begin looping through lines from\n",
    "data[1:]. We now need to use an if statement to process different lines in a different way.\n",
    "Where a line’s length is only 1, we know that this just contains a reference number that we\n",
    "don’t need. Because we start our loop from the second line of the raw data, we also know that\n",
    "a line of length 1 means that the sentences we have seen before make up one whole abstract.\n",
    "Applying this logic to our loop, when we see len(line) == 1, we can use append() to\n",
    "append an abstract to our clean data list, and initialize a new empty abstract string. If we have a\n",
    "line that is not of length 1, we can add the current line’s second element to the abstract string to\n",
    "build up a complete abstract from several lines of text and ignore the sentence type annotation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = []\n",
    "abstract = ''\n",
    "\n",
    "for line in data[1:]:\n",
    "    if len(line) == 1:\n",
    "        clean_data.append(abstract)\n",
    "        abstract = ''\n",
    "    else:\n",
    "        abstract += ' ' + line[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we just need to write our data back to the file so that we don’t need to do this cleaning\n",
    "step every time our knowledge graph is constructed later. We can use the csv module again\n",
    "to write each abstract to a separate line. We can also take this opportunity to give each abstract\n",
    "a sequentially increasing integer ID, which igraph will require later, by using enumerate():"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingesting data into a Knowledge Graph\n",
    "There are some stuff jumping straight into creating a knowledge graph from our cleaned abstract data. We must consider the structure we are aiming to produce first. We will then need to process our abstracts to extract terms of interest. Then, once we have terms, we can create a list of edges to import into igraph.\n",
    "\n",
    "Getting the ingestion right into the knowledge graph is crucial and this all stems from how you\n",
    "conceptually and practically design your graph schema."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
